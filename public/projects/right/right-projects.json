{
	"1": {
		"id": 1,
		"title": "Electronic Music Production",
		"description": "I produce experimental and ambient electronic music using my laptop, inspired by artists like Porter Robinson, Kasbo, and Tourist.",
		"image": "/images/right/fl.png",
		"technologies": [
		  "Music Production",
		  "Sound Design",
		  "Mixing",
		  "Mastering",
		  "FL Studio"
		],
		"link": "https://soundcloud.com/raven-714331711",
		"liveLink": "https://soundcloud.com/raven-714331711",
		"blog": "I'm really into making experimental and ambient electronic music on my laptop. Artists like Porter Robinson, Kasbo, and Tourist are a big influence on the kind of sounds I try to create. I usually explore with weird textures and atmospheres through synthesis (synplant) and sampling (granular go brr) . I do most of the mixing while picking the sounds and composing as I see no point in doing not so fun things in my hobby time.\n\nThe goal is to craft these positive listening experiences that can take you to a different headspace. Not trying to reinvent the wheel or anything, but I dig pushing my own boundaries and seeing what unique little worlds I can build out of digital sound. It's a fun creative outlet for me, even if hardly anyone hears the tunes. At the end of the day, I'm just enjoying the journey of being an amateur electronic musician who likes to experiment.",
		"videoLink": ""
	  },
	"2": {
	  "id": 2,
	  "title": "Guitar and Singing Covers",
	  "description": "I post guitar and singing covers on my Instagram, mostly featuring songs by Ed Sheeran.",
	  "image": "/images/right/edandshawn.png",
	  "technologies": ["Guitar", "Singing", "Music"],
	  "liveLink": "https://www.instagram.com/floare_dor/",
	  "blog": "I'm really into music, especially playing guitar and singing covers. On my Instagram, I post videos of me performing songs that I enjoy listening to. A lot of my covers are Ed Sheeran and Porter Robinson tunes since I connect with the emotional, melodic style.",
	  "videoLink": ""
	},
	"3": {
	  "id": 3,
	  "title": "Audio-Reactive Landscape Visuals with StyleGAN3",
	  "description": "Trained a custom StyleGAN3 model on NVIDIA's DGX-1 to generate audio-reactive landscape visuals for my DJ set, utilizing transfer learning and synchronizing visuals with spectral audio features using LibROSA.",
	  "image": "/images/right/stylegan3.png",
	  "technologies": ["StyleGAN3", "Transfer Learning", "Audio Analysis", "LibROSA"],
	  "liveLink": "https://drive.google.com/file/d/1zsproXF5oHc_7pXAzTnYQt-vwy54-X6N/view?usp=sharing",
	  "blog": "Combining my passion for music and visual arts, I tried to generate audio-reactive landscape visuals for my DJ sets. By training a custom StyleGAN3 model on NVIDIA's powerful DGX-1 system, I had done a bit of transfer learning to create interesting visuals that synchronize with the spectral features of the music. Leveraging the LibROSA library for audio analysis, I developed a system that translates the rhythm, intensity, and emotions of the music into visual landscapes, in an attempt to make the set experience cool.",
	  "videoLink": ""
	},
	"4": {
	  "id": 4,
	  "title": "Music-Based Interactive To-Do List",
	  "description": "Developed a music-based interactive to-do list site that integrates music with task management.",
	  "image": "/images/right/to-do-list.png",
	  "technologies": ["WebDev", "Vue.js", "Python", "JavaScript"],
	  "githubLink": "https://github.com/FloareDor/to-do-list",
	  "liveLink": "https://to-do-list-rose-theta.vercel.app/",
	  "blog": "Just a simple productivity tool that brings sound into the UX. The idea seemed exciting to me back then and that's also the first time I've used an FE framework. Sometimes having a some audio playing can help make repetitive tasks feel less tedious. It's a small thing, but I thought combining those two elements could potentially improve the experience for some people.",
	  "videoLink": ""
	},
	"5": {
		"id": 5,
		"title": "Top-Down Horror Game with Godot",
		"description": "Developed a top-down horror game using the Godot game engine and won a small game jam.",
		"image": "/images/right/gamejam.png",
		"technologies": ["Godot", "GameDev"],
		"githubLink": "https://github.com/FloareDor/AloneGamejam",
		"liveLink": "https://floaredor.itch.io/eclipse-of-the-solitary",
		"blog": "Made this in a day or two after a long long break from Gamedev. Honestly, this is my first complete (fairly complete) game. Idek how I won that GameJam with this but it was fun working on path tracing.\n\nOne of the first things I tackled was the door animation. As someone relatively new to the game engine and animationTree, it was a pretty satisfying achievement. It took some time to figure out, but seeing that door open and close smoothly made it all worth it.\n\nI'm also quite happy with how the sound design turned out, especially the door thud sound. I created it myself using some heavy distortion and EQ tweaks. It's not perfect, but it adds a nice touch to the overall atmosphere of the game.\n\nSince my main focus was on the programming side of things, I decided to ask GPT-4 to help me out with creating the game map. To my surprise, it did a really good job! Of course, I still had to spend a couple of hours adding proper collisions to the map, making sure the player couldn't walk through walls or fall through the floor. But it saved me a lot of time and effort in the long run.\n\nOverall, it was me having no clue and building shit for 2 days, which made me see the beauty in well.. building shit. (Thanks to the lads at Enigma) \n\nAtm, diving into the Graphics coursework is itching me to try to make games using just C++ and a windows api but we'll see how that goes.",
		"videoLink": ""
	},
	"6": {
	  "id": 6,
	  "title": "Emotion-Specific Sound Generation",
	  "description": "Developed an emotion-specific sound generation tool using evolutionary algorithms, self-organizing maps, and Fuzzy C-means clustering.",
	  "image": "/images/right/eq.png",
	  "technologies": ["MIR", "Evolutionary Algorithms", "SOM", "Fuzzy"],
	  "githubLink": "https://github.com/FloareDor/Sound-Genes",
	  "liveLink": "",
	  "blog": "I worked on this cool research project that used AI to generate sounds based on specific emotions. The idea was to see if machine learning could be applied to create audio with an intended vibe or feeling behind it. Using some MIR techniques, alongside a crazy talented team, I built an algorithm that analyzed different sound characteristics and clustered them into emotional categories. It basically solved for the right amplitude and phase values to produce sounds that aimed to evoke a target emotion like happiness, sadness, etc. It was just an experimental project, but the concept could potentially be useful for music composers or sound designers looking to craft emotional soundscapes and atmospheres in an novel way. Not saying I cracked the code on computationally generating feelings through audio or anything. But it was a fun chance to combine my interests in music and AI/machine learning.",
	  "videoLink": ""
	},
	"7":{
		"id": 7,
		"title": "Battleship Codeathon",
		"description": "An implementation of the classic Battleship game where teams submit Python programs to play against each other in a competitive programming competition.",
		"image": "/images/right/battleship.png",
		"technologies": [
		  "Python",
		  "GameDev"
		],
		"githubLink": "https://github.com/FloareDor/BattleShip-BattleGround",
		"liveLink": "",
		"blog": "Organizing a competitive programming competition around the classic Battleship game was good fun. Instead of traditional human players, teams had to submit Python programs that would play the game against each other autonomously. The project was built using PyGame.\n\nThe core of the competition revolved around the BattleShip class, which teams had to implement with specific member variables and functions. This class handled ship placement, attack coordination, and hit/miss tracking. Teams were required to submit a Python file containing this class, adhering to predefined method signatures.\n\nWe automated gameplay between teams' programs. The game engine would set up the battlefields, place ships based on the team's code, and facilitate the attack-defend loop, providing hit/miss information to the programs for further decision-making.\n\nTo keep things interesting, we introduced special moves like 'Nullify' and 'Missile Hawkeye,' adding strategic depth to the gameplay. The 'Nullify' move allowed teams to nullify their opponent's next chance, effectively giving them a double hit. The 'Missile Hawkeye' move enabled teams to eliminate an entire row and column with a single hit, mimicking a cross-shaped attack.\n\nAnother interesting aspect was the board representation and ship placement rules. Teams had to follow a predefined format to set up their ships, ensuring fair and consistent gameplay across all teams. The attack and hit/miss tracking mechanisms were also carefully crafted to provide meaningful information to the programs while maintaining the excitement of the game.\n\nOverall, this project combined our love for game development and programming in general. It challenged teams to think strategically, optimize their algorithms, and write robust code to outmaneuver their opponents. Seeing the programs battle it out in the Battleship arena was entertaining, presenting the creativity and problem-solving skills of the participants.",
		"videoLink": ""
	  }
  }